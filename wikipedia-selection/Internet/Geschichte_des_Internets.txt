Die Geschichte des Internets lässt sich in drei Phasen einteilen. In der Frühphase ab Mitte der 1960er Jahre wurden die Grundlagen gelegt, die Technik demonstriert und zur Anwendungsfähigkeit entwickelt. Ende der 1970er Jahre, gleichzeitig mit dem Wechsel von der militärischen zur akademischen Forschungsförderung, begann das Wachstum und die internationale Ausbreitung des Internets. In dieser Zeit geschah das, was gemeinhin mit der wilden Phase des ursprünglichen Internet assoziiert wird: eine Tauschökonomie für Software und Information, eine graswurzelbasierte Selbstorganisation, sich entwickelnde Communitys und der Hackergeist, der jede Beschränkung des Zugangs und des freien Informationsflusses zu umgehen weiß. 1990 begann mit der Abschaltung des Arpanet die kommerzielle Phase des Internets. Es wird geschätzt, dass im Jahr 1993 das Internet lediglich 1 % der Informationsflüsse der weltweiten Telekommunikationsnetze ausmachte, während es im Jahr 2000 bereits die Mehrheit des technischen Informationsaustausches beherrschte (51 %) und im Jahr 2007 bereits klar dominierte (97 % der Bytes, die weltweit ausgetauscht wurden).Obgleich im Artikel eine chronologische Darstellung überwiegt, ist er in erster Linie thematisch gegliedert. Eine chronologische Auflistung der Ereignisse findet man im Artikel Chronologie des Internets.Das Internet ist mediengeschichtlich eine Anomalie. Übliche Modelle der Medien- wie der Technikgenese allgemein laufen vom Labor über die Entwicklung hin zur Anwendungsreife bis zur gesellschaftlichen Implementierung entweder als staatliche Militär- oder Verwaltungskommunikation, als wirtschaftliches Kontroll- und Steuerungsinstrument oder als Massenprodukt der Individualkommunikation bzw. der Massenmedien. Anders hingegen im Falle von akademischen Datennetzen. Hier gab es in den ersten Jahren keine Trennung zwischen Erfindern, Entwicklern und Anwendern. Die Informatik hat im Netz nicht nur ihren Forschungsgegenstand, sondern zugleich ihr Kommunikations- und Publikationsmedium. Es ist gleichzeitig Infrastruktur und Entwicklungsumgebung, die von innen heraus ausgebaut wird. Innovationen werden von den Entwickler-Anwendern in der Betaversion, das heißt ohne Garantie und auf eigene Gefahr, in die Runde geworfen, von den Kollegen getestet und weiterentwickelt. Darüber hinaus stellt sie den anderen, zunehmend computerisierten, Wissenschaften die gleiche Infrastruktur zur Verfügung. Der Zugang zu Rechenressourcen, der Austausch innerhalb einer weltweiten Community von Fachkollegen, das Zur-Diskussion-Stellen von Preprints, die Veröffentlichung von Konferenzreferaten und Datenbanken im Internet – all dies gehört seit den 1980er Jahren zu den täglichen Praktiken in der Physik und Astronomie, der Informatik selbst und zunehmend auch in den weicheren Wissenschaften. Schließlich ist das Weiterreichen der Grundwerkzeuge an die Studierenden Teil der wissenschaftlichen Lehre. Da das Netz, anders als die meisten Laborgeräte, keinen eng definierten Anwendungsbereich hat, sondern eben Medium ist, stoßen hier auch studentische, private und Freizeitkulturen auf eine brisante Mischung aus High Tech und Hobbyismus, Science und Science Fiction, Hackern und Hippies.Als früheste Vision einer möglichen weltweiten Computer-Vernetzung gilt eine Kurzgeschichte des Science-Fiction-Autors Murray Leinster, der 1946 in seiner Story A Logic Named Joe als einer der ersten einen Personal Computer und eine frühe Vision des Internets geschildert hat; dort hat er geschrieben, der Computer … erledigt die Verbreitung von vierundneunzig Prozent aller Fernsehprogramme, vermittelt alle Informationen über Wetter, Luftverkehr, Sonderangebote … und dokumentiert jedes geschäftliche Gespräch, jeden Vertrag … Die Computer haben die Welt verändert. Die Computer sind die Zivilisation. Wenn wir die Computer abschalten, fallen wir in eine Art von Zivilisation zurück, von der wir vergessen haben, wie sie geht.In den späten 1950er Jahren leitete J. C. R. Licklider eine Forschungsgruppe beim US-Rüstungslieferanten Bolt Beranek and Newman (BBN), deren Arbeit auf dem Minicomputer PDP-1 des Herstellers Digital Equipment Corporation (DEC), einem der ersten Time-Sharing-Systeme, aufbaute. Computerhersteller und die meisten Vertreter des Informatik-Establishments waren jedoch der Ansicht, dass Time-Sharing eine ineffiziente Verwendung von Computerressourcen darstelle und nicht weiter verfolgt werden solle. Lickliders Argument war umgekehrt, dass Rechner für eine Echtzeit-Interaktion für „kooperatives Denken mit einem Menschen“ zu schnell und zu kostspielig seien, weshalb sie ihre Zeit zwischen vielen Nutzern aufteilen müssten. Licklider war auch der Architekt des MAC-Projektes (Multiple-Access Computer, auch als Machine-Aided Cognition oder Man And Computer bekannt) am Massachusetts Institute of Technology (MIT). 1962 wechselte er von BBN zur Advanced Research Projects Agency (ARPA) des US-Verteidigungsministeriums, wo er Leiter des Command and Control Research (CCR) wurde, das er sogleich in Information Processing Techniques Office (IPTO) umbenannte. Seine Erfahrungen mit Time-Sharing-Systemen erlaubten es ihm, eine Neudefinition vom Computer als Rechenmaschine zum Computer als Kommunikationsgerät vorzunehmen. Als Leiter des ARPA-Forschungsbereiches war er nun in die Lage versetzt, diesen Paradigmenwechsel in der Netzplanung zur Wirkung zu bringen: Gleichzeitig fand ein telekommunikationstechnischer Paradigmenwechsel von leitungsorientierten zu paketvermittelten Konzepten statt. Er ging auf parallele Arbeiten von Paul Baran an der Rand Corporation (die erste Denkfabrik, 1946 von der U.S. Air Force gegründet) und von Donald Watts Davies am National Physical Laboratory in Middlesex, England, zurück. Paul Baran veröffentlichte 1960 ein Paper, in dem er einen drohenden Nuklearkrieg als Anlass nahm, Ideen für ein Netzwerk zu entwickeln, welches einen solchen Krieg überleben könnte. Die Zerlegung von Kommunikationen in kleine Datenpakete, die, mit Ziel- und Absenderadresse versehen, quasi autonom ihren Weg durch das Netzwerk finden, war Voraussetzung für die verteilte, dezentrale Architektur des Internets. Sie war auch der Punkt, an dem die Geister der Computer- und der Telekommunikationswelt sich schieden. Die Telefonbetreiber der Zeit waren durchaus an Datenkommunikation sowie an der Paketvermittlung interessiert, nachdem nachgewiesen worden war, dass diese Technik nicht nur überhaupt machbar war, sondern dass sie die vorhandene Bandbreite viel wirtschaftlicher nutzte als die Leitungsvermittlung, doch die vorrangigen Designkriterien der nationalen Monopole waren flächendeckende Netzsicherheit, Dienstequalität und Abrechenbarkeit. Diese sahen sie nur durch ein zentral gesteuertes Netz mit dedizierter Leitungsnutzung für jede einzelne Kommunikation gewährleistet. Die Telekommunikationsunternehmen vor allem in England, Italien, Deutschland und Japan unterlegten daher den unberechenbaren Paketflüssen eine virtuelle Kanalstruktur. Auch in diesem System werden Pakete verschiedener Verbindungen auf derselben physikalischen Leitung transportiert, aber nur bis zu einer Obergrenze, bis zu der die Kapazität für jede einzelne Verbindung gewährleistet werden kann. Außerdem ist dieses Netz nicht verteilt, sondern über zentrale Vermittlungsstellen geschaltet. Die Spezifikationen dieses Dienstes wurden im Rahmen der Internationalen Fernmeldeunion (ITU) verhandelt und 1976 unter der Bezeichnung X.25 standardisiert. Die Bundespost bot ihn unter dem Namen Datex-P an. Damit ist der Gegensatz aufgespannt zwischen einem rhizomatischen Netz, das aus einem militärischen Kalkül heraus von einzelnen Knoten aus dezentral wuchert, und einer hierarchischen, baumförmigen Struktur, die zentral geplant und verwaltet wird. Die ARPA-Forschungsabteilung unter Licklider schrieb die verschiedenen Bestandteile des neuen Netzes aus. Das Stanford Research Institute (SRI) erhielt den Auftrag, die Spezifikationen für das neue Netz zu schreiben. Im Dezember 1968 legte das SRI den Bericht A Study of Computer Network Design Parameters vor. Zur selben Zeit arbeitete Douglas C. Engelbart und seine Gruppe am SRI bereits an computergestützten Techniken zur Förderung von menschlicher Interaktion. Daher wurde entschieden, dass das SRI der geeignete Ort sei, ein Network Information Center (NIC) für das ARPAnet einzurichten. Die DARPA-Ausschreibung für ein Network Measurement Center ging an die University of California, Los Angeles (UCLA), wo Leonard Kleinrock arbeitete, der seine Doktorarbeit über Warteschlangentheorie geschrieben hatte. Ebenfalls im UCLA-Team arbeiteten damals Vinton G. Cerf, Jonathan Postel und Steve Crocker. Den Zuschlag für die Entwicklung der Paketvermittlungstechniken, genauer eines Interface Message Processors (IMP), erhielt BBN. Dort arbeitete unter anderem Robert E. Kahn, der vom MIT gekommen war und auf den ein Großteil der Architektur des Internets (TCP/IP) zurückgeht. Die IMPs, Vorläufer der heutigen Router, hatten die Aufgabe, die niedrigste Verbindungsschicht zwischen den über Telefonleitungen vernetzten Rechnern (Hosts) herzustellen. Die ersten IMPs wurden im Mai 1969 ausgeliefert. Der Startschuss zum Internet fiel im Herbst 1969, als die ersten vier Großrechner in der UCLA, im SRI, der University of California in Santa Barbara (UCSB) und der University of Utah miteinander verbunden wurden. Am 29. Oktober 1969 war „Io“ die erste gelungene Internetbotschaft, die versuchsweise von der UCLA an das Stanford Research Institut übermittelt wurde.Bereits ein halbes Jahr vorher war das erste von Tausenden von Request for Comments-Dokumenten (RFCs) erschienen, die die technischen Standards des Internets spezifizieren. Diese Standards werden nicht im Duktus eines Gesetzes erlassen, sondern als freundliche Bitte um Kommentierung. Steve Crocker begründete als Autor des ersten RFC diese Form damit, dass die Beteiligten nur Doktoranden ohne jede Autorität waren. Sie mussten daher einen Weg finden, ihre Arbeit zu dokumentieren, ohne dass es schien, als wollten sie irgendjemandem etwas aufdrängen, sprich in einer Form, die offen für Kommentare war. RFCs können von jedem erstellt werden. Sie sind als Diskussionspapiere gedacht, mit dem erklärten Ziel, die Autorität des Geschriebenen zu brechen. Neben den meist technischen Texten werden auch die Philosophie (zum Beispiel RFC 1718), die Geschichte (RFC 2235) und die Kultur des Netzes aufgezeichnet und zuweilen sogar gedichtet (RFC 1121). Die freie Verfügbarkeit der Spezifikationen und der dazugehörigen Referenzimplementationen waren ein Schlüsselfaktor bei der Entwicklung des Internets. Aus dem ersten RFC ging ein Jahr später das Network Control Protocol (NCP) hervor, ein Satz von Programmen für die Host-Host-Verbindung, das erste Arpanet-Protokoll. 1971 bestand das Netz aus 14 Knoten und wuchs um einen pro Monat. Nach Fertigstellung des NCP und Implementierung für die verschiedenen Architekturen entstanden jetzt die höheren Dienste Telnet (RFC 318) und FTP (File Transfer Protocol, RFC 454). Ray Tomlinson von BBN modifizierte ein E-Mail-Server-Programm für das Arpanet und erfand die user@host-Konvention. Larry Roberts schrieb hierfür einen Mail-Client. Das Netzwerk konnte sich sehen lassen. Es war Zeit für eine erste öffentliche Demonstration, die 1972 auf der International Conference on Computer Communications in Washington stattfand. Im Keller des Konferenzhotels wurde ein Paketvermittlungsrechner und ein Terminal Interface Processor (TIP) installiert, der anders als ein IMP den Input von mehreren Hosts oder Terminals verarbeiten konnte. Angeschlossen waren 40 Maschinen in den ganzen USA. Zu den Demonstrationen gehörten interaktive Schachspiele und die Simulation eines Luftverkehrskontrollsystems. Berühmt wurde die Unterhaltung zwischen ELIZA, Joseph Weizenbaums künstlich-intelligentem Psychiater am MIT, und PARRY, einem paranoiden Programm von Kenneth Colby an der Stanford-Universität. Teilnehmer aus England, Frankreich, Italien und Schweden waren dabei. Vertreter von AT&T besuchten die Konferenz, verließen sie jedoch in tiefer Verwirrung. Im selben Jahr starteten Projekte für radio- und satellitengestützte Paketvernetzung, letztere mit Instituten in Norwegen und England. Bob Metcalfe umriss in seiner Doktorarbeit an der Harvard-Universität das Konzept für ein Local Area Network (LAN) mit multiplen Zugangskanälen, das er Ethernet nannte. Am Xerox PARC entwickelte er das Konzept weiter, bevor er später 3Com gründete. Arpanet, SATNET und das Radionetz hatten verschiedene Schnittstellen, Paketgrößen, Kennzeichnungen und Übertragungsraten, was es schwierig machte, sie untereinander zu verbinden. Bob Kahn, der von BBN an die DARPA ging, und Vint Cerf, der jetzt an der Stanford-Universität unterrichtete, begannen, ein Protokoll zu entwickeln, um verschiedene Netze miteinander zu verbinden. Sie orientierten sich dabei an den Entwicklungen des CYCLADES-Projekts. Im Herbst 1973 stellten sie auf einem Treffen der International Network Working Group in England den ersten Entwurf zum Transmission Control Protocol (TCP) vor. Im Jahr darauf wurde TCP gleichzeitig an der Stanford University, bei BBN und dem University College London (Peter Kirstein) implementiert. Es folgten vier Iterationen des TCP-Protokollsatzes. Die letzte erschien 1978. 1974 startete BBN Telenet, den ersten öffentlichen paketvermittelten Datenkommunikationsdienst als eine kommerzielle Version des Arpanet. Aufgrund der DARPA-Förderung besaß BBN kein exklusives Recht am Quellcode für die IMPs und TIPs. Andere neue Netzwerkunternehmen forderten BBN auf, diesen freizugeben. BBN sträubte sich zunächst, da der Code ständig verändert würde, gab ihn jedoch 1975 frei.Mit der Forschungsförderung für die Implementierung von TCP hatte die DARPA ihre initiale Mission erfüllt. 1975 wurde die Verantwortung für das Arpanet an die Defense Communications Agency (später umbenannt in Defense Information Systems Agency) übertragen. BBN blieb der Auftragnehmer für den Betrieb des Netzes, doch militärische Sicherheitsinteressen wurden jetzt wichtiger. Zusätzlich zur DARPA förderte auch die National Science Foundation (NSF) die Forschung in Informatik und Netzwerken an rund 120 US-amerikanischen Universitäten. Weitere Einrichtungen, wie das Energieministerium und die NASA starteten eigene Netzwerke. Anfang 1975 verfügte das Arpanet über 61 Knoten. Die erste Mailingliste wurde eingerichtet. Zusammen mit den RFCs werden Mailinglisten zum wichtigsten Mittel der offenen Kooperation der technischen Community. In der beliebtesten Liste dieser Zeit diskutierte man jedoch über Sciencefiction. Das Jargon File, ein Wörterbuch der Hacker-Kultur, zusammengestellt von Raphael Finkel, wurde zum ersten Mal publiziert, natürlich im Netz. UUCP (Unix to Unix Copy) wurde 1976 an den AT&T Bell Labs entwickelt und als Teil der Unix Version 7 verbreitet. Einrichtungen, die sich keine Standleitung leisten konnten, ermöglichte es UUCP, über Wählverbindungen auf normalen Telefonleitungen Daten 